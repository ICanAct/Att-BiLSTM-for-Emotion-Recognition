{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r_rhwySD4mjo",
    "outputId": "7e1ab0e1-301b-4641-c3af-8e5aabfc5a95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweet-preprocessor\n",
      "  Using cached tweet_preprocessor-0.6.0-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: tweet-preprocessor\n",
      "Successfully installed tweet-preprocessor-0.6.0\n"
     ]
    }
   ],
   "source": [
    "# dependencies. \n",
    "## colab version (Uncomment the below line)\n",
    "\n",
    "#!pip install tweet-preprocessor\n",
    "\n",
    "##Jupyter notebook version\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install tweet-preprocessor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_mYVnW4x444s",
    "outputId": "420b100d-92c5-4ab2-ba14-a7add65ad7af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/krishnavyas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/krishnavyas/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/krishnavyas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, os, csv\n",
    "import itertools, pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "from collections import Counter\n",
    "from tensorflow.keras.preprocessing import text\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "import nltk\n",
    "import statistics\n",
    "import preprocessor as p\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWTMIBRd5CF8",
    "outputId": "03250792-11f6-4fea-f261-8dc5a693c140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content  sentiment\n",
      "0  do not get angry or frustrated or desperate or...          4\n",
      "1  sickening i hurt for florida later for the wha...          4\n",
      "2  this rainfall is a savage y fall when am in d ...          4\n",
      "3  angry guy screws his gf in very rude manner po...          4\n",
      "4  silence is better when you re angry and frustr...          4\n"
     ]
    }
   ],
   "source": [
    "# Loading the data.\n",
    "raw_data = pd.read_csv('tweet_data.csv', names=[\"content\", \"sentiment\"])\n",
    "raw_data = raw_data.dropna()\n",
    "cleaned_data = raw_data.reset_index(drop = True)\n",
    "print(cleaned_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "aSV9NbGvBSup"
   },
   "outputs": [],
   "source": [
    "# changing the labels into one hot vectors for training. \n",
    "y_data = to_categorical(cleaned_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "NKUDjEM6554e",
    "outputId": "1f9121c6-b333-4a44-93e9-f7c42dba40a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do not get angry or frustrated or desperate or...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sickening i hurt for florida later for the wha...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this rainfall is a savage y fall when am in d ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>angry guy screws his gf in very rude manner po...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>silence is better when you re angry and frustr...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  sentiment\n",
       "0  do not get angry or frustrated or desperate or...          4\n",
       "1  sickening i hurt for florida later for the wha...          4\n",
       "2  this rainfall is a savage y fall when am in d ...          4\n",
       "3  angry guy screws his gf in very rude manner po...          4\n",
       "4  silence is better when you re angry and frustr...          4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning the data. \n",
    "cleaned_data['content'] = cleaned_data['content'].map(p.clean)\n",
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "hnK1i7-q6R0r"
   },
   "outputs": [],
   "source": [
    "## Code to preprocess tweet data.\n",
    "\n",
    "def preprocess_data(data):\n",
    "  #Removes Numbers\n",
    "  data = data.astype(str).str.replace('\\d+', '')\n",
    "  lower_text = data.str.lower()\n",
    "  lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "  w_tokenizer =  TweetTokenizer()\n",
    "  \n",
    "  def lemmatize_text(text):\n",
    "    return [(lemmatizer.lemmatize(w)) for w \\\n",
    "                        in w_tokenizer.tokenize((text))]\n",
    "  def remove_punctuation(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', (word))\n",
    "        if new_word != '':\n",
    "          new_words.append(new_word)\n",
    "    return new_words\n",
    "  words = lower_text.apply(lemmatize_text)\n",
    "  words = words.apply(remove_punctuation)\n",
    "  return pd.DataFrame(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "lXi5AnMg7fA-",
    "outputId": "de46f90a-cd7c-45a3-fbc4-9af170dcf95b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[do, not, get, angry, or, frustrated, or, desp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[sickening, i, hurt, for, florida, later, for,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[this, rainfall, is, a, savage, y, fall, when,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[angry, guy, screw, his, gf, in, very, rude, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[silence, is, better, when, you, re, angry, an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0  [do, not, get, angry, or, frustrated, or, desp...\n",
       "1  [sickening, i, hurt, for, florida, later, for,...\n",
       "2  [this, rainfall, is, a, savage, y, fall, when,...\n",
       "3  [angry, guy, screw, his, gf, in, very, rude, m...\n",
       "4  [silence, is, better, when, you, re, angry, an..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_tweets = preprocess_data(cleaned_data['content'])\n",
    "pre_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "DmNFnrIW8DtY",
    "outputId": "9dd95100-5074-4585-bb7e-7a9afcac00d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[get, angry, frustrated, desperate, enraged, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[sickening, hurt, florida, later, know, feel, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[rainfall, savage, fall, club, n, home, hot, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[angry, guy, screw, gf, rude, manner, portsmouth]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[silence, better, angry, frustrated, reacting,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0  [get, angry, frustrated, desperate, enraged, d...\n",
       "1  [sickening, hurt, florida, later, know, feel, ...\n",
       "2  [rainfall, savage, fall, club, n, home, hot, l...\n",
       "3  [angry, guy, screw, gf, rude, manner, portsmouth]\n",
       "4  [silence, better, angry, frustrated, reacting,..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## code for removing stop words. \n",
    "stop_words = set(stopwords.words('english'))\n",
    "pre_tweets['content'] = pre_tweets['content'].apply(lambda x: [item for item in \\\n",
    "                                    x if item not in stop_words])\n",
    "\n",
    "pre_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZBFZfCRv81tu"
   },
   "outputs": [],
   "source": [
    "# sentence length data for statistics. \n",
    "word_count_list = []\n",
    "for sentence in pre_tweets['content']:\n",
    "  word_count_list.append(len(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Z0_FDHC1_zQg"
   },
   "outputs": [],
   "source": [
    "# Tokenising the tweet data.\n",
    "word_tokenizer = text.Tokenizer()\n",
    "word_tokenizer.fit_on_texts(pre_tweets['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zOs5R0ph_5eM"
   },
   "outputs": [],
   "source": [
    "vocab_length = len(word_tokenizer.word_index) + 1\n",
    "embedded_sentences = word_tokenizer.texts_to_sequences(pre_tweets['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wy4v7PNsAS_3",
    "outputId": "5670d334-8103-4b21-9953-c8bbfa0b1a15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n",
      "7.578549336948693\n",
      "3.990504137584777\n"
     ]
    }
   ],
   "source": [
    "# stats to decide on the optimal length of the sentence.\n",
    "median_length = statistics.median(word_count_list)\n",
    "print(median_length)\n",
    "mean_length = statistics.mean(word_count_list)\n",
    "print(mean_length)\n",
    "st_dev = statistics.stdev(word_count_list)\n",
    "print(st_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Dp_dEznw910f"
   },
   "outputs": [],
   "source": [
    "# set the sentence length here based on the above stats. \n",
    "SENTENCE_LENGTH = 15\n",
    "padded_sentences = pad_sequences(embedded_sentences, SENTENCE_LENGTH, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "nFmdKNgMAa5J",
    "outputId": "24012502-f47b-4ec0-f002-1a1f7aa34f27"
   },
   "outputs": [],
   "source": [
    "# loading standard Glove vectors\n",
    "embeddings_dictionary = dict()\n",
    "glove_file = open('glove.twitter.27B.50d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "odbu8JytAg4U"
   },
   "outputs": [],
   "source": [
    "# Embedding the words\n",
    "embedding_matrix = np.zeros((vocab_length, 50))\n",
    "for word, index in word_tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "4H_7cHwHBC4s"
   },
   "outputs": [],
   "source": [
    "# Test - Train split. \n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sentences, y_data, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "IPi5u7u9hCmU"
   },
   "outputs": [],
   "source": [
    "# Attention layer Implementation. \n",
    "\n",
    "class attention(Layer):\n",
    "    \n",
    "    def __init__(self, return_sequences=True):\n",
    "        self.return_sequences = return_sequences\n",
    "        super(attention,self).__init__()\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),\n",
    "                               initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n",
    "                               initializer=\"zeros\")\n",
    "        \n",
    "        super(attention,self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x*a\n",
    "        \n",
    "        if self.return_sequences:\n",
    "            return output\n",
    "        \n",
    "        return K.sum(output, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "I-lKL8bKB2yu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 15, 50)            1509000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 50)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 15, 128)           58880     \n",
      "_________________________________________________________________\n",
      "attention (attention)        (None, 128)               143       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,568,668\n",
      "Trainable params: 59,668\n",
      "Non-trainable params: 1,509,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model for learning (Attention - Bidirectional LTSM)\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_length, \n",
    "                           50,\n",
    "                           weights=[embedding_matrix],\n",
    "                           input_length=SENTENCE_LENGTH, \n",
    "                           trainable=False))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Bidirectional(\n",
    "    layers.LSTM(64, dropout=0.3, \n",
    "                kernel_regularizer=tf.keras.regularizers.l2(1e-5), \n",
    "                return_sequences=True)))\n",
    "model.add(attention(return_sequences=False))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(5, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bFnZXy7wCBUA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37764 samples, validate on 9442 samples\n",
      "Epoch 1/250\n"
     ]
    }
   ],
   "source": [
    "# Model optimiser and training code.\n",
    "opt = tf.keras.optimizers.Adadelta(learning_rate=1.0)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=250,\n",
    "                    verbose=2,\n",
    "                    use_multiprocessing=True,                   \n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-ZvGda3jPuD"
   },
   "outputs": [],
   "source": [
    "# Create a directory for saving figures.\n",
    "if not os.path.isdir('figures'):\n",
    "    os.makedirs('figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8wKQwZN2CL9R"
   },
   "outputs": [],
   "source": [
    "# Accuracy plot for the model. \n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Attention BiLSTM Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig('./figures/Bilstm_accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6BsKeD1vjRfW"
   },
   "outputs": [],
   "source": [
    "# Loss plot for the Model.\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Attention BiLSTM Model loss')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig('./figures/Bilstm_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQ_TQbTNj4dC"
   },
   "outputs": [],
   "source": [
    "# prediction on test data for prediction Metrics\n",
    "y_pred = model.predict(X_test)\n",
    "Y_test = np.argmax(y_test, axis=1) \n",
    "y_pred_class = np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YXk-nr6WcFii"
   },
   "outputs": [],
   "source": [
    "# Classification report for the predicted results.\n",
    "\n",
    "classes = [\"neutral\", \"happy\", \"sad\", \"hate\",\"anger\"]\n",
    "print(classification_report(Y_test, y_pred_class, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inV85J9ocmFC"
   },
   "outputs": [],
   "source": [
    "# Confusion matrix for results visualistaion\n",
    "\n",
    "cnf_matrix = confusion_matrix(Y_test, y_pred_class)\n",
    "\n",
    "def plot_confusion_matrix(cm, labels,\n",
    "                          normalize=True,\n",
    "                          title='Confusion Matrix (Validation Set)',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        #print('Confusion matrix, without normalization')\n",
    "        pass\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig('conf_matrix.png')\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_confusion_matrix(cnf_matrix, labels=classes)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GLOVE_Att_BILSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
